GroupInvariant Quantum Machine Learning Martn Larocca1 2 Frdric Sauvage1 Faris M Sbahi3 4 Guillaume Verdon3 5 6 Patrick J Coles1 7 and M Cerezo8 7 1Theoretical Division Los Alamos National Laboratory Los Alamos New Mexico 87545 USA 2Center for Nonlinear Studies Los Alamos National Laboratory Los Alamos New Mexico 87545 USA 3X Mountain View CA 94043 USA 4Google Brain Mountain View CA 94043 USA 5Institute for Quantum Computing University of Waterloo ON Canada 6Department of Applied Mathematics University of Waterloo ON Canada 7Quantum Science Center Oak Ridge TN 37931 USA 8Information Sciences Los Alamos National Laboratory Los Alamos NM 87545 USA Quantum Machine Learning QML models are aimed at learning from data encoded in quantum states Recently it has been shown that models with little to no inductive biases ie with no assumptions about the problem embedded in the model are likely to have trainability and gener alization issues especially for large problem sizes As such it is fundamental to develop schemes that encode as much information as available about the problem at hand In this work we present a simple yet powerful framework where the underlying invariances in the data are used to build QML models that by construction respect those symmetries These socalled groupinvariant mod els produce outputs that remain invariant under the action of any element of the symmetry group G associated to the dataset We present theoretical results underpinning the design of Ginvariant models and exemplify their application through several paradigmatic QML classication tasks in cluding cases when G is a continuous Lie group and also when it is a discrete symmetry group Notably our framework allows us to recover in an elegant way several well known algorithms for the literature as well as to discover new ones Taken together we expect that our results will help pave the way towards a more geometric and grouptheoretic approach to QML model design I INTRODUCTION Symmetries have always held a special place in the imag inarium of scientists seeking to understand the universe through physical theories As such it is not strange for a scientist to equate a theorys beauty and elegance with its symmetry and harmony 1 Still the role of symmetries in science is more than simply aesthetic as in many cases they constitute the underlying force behind a theory For instance Galilean invariance is pivotal in Newtons laws of motion 2 and Lorentz and gauge invariances were fun damental for Maxwell to unify electricity and magnetism into the general theory of electromagnetism 3 In the 20th century symmetries would take the center stage as Einsteins theory of general relativity provided the rst ge ometrization of symmetries 4 5 Soon after Noethers theorem showed a connection between dierentiable sym metries and conserved quantities 6 proving that symme tries have dening implications in nature More recently the importance of symmetries has been explored in the context of machine learning and is core to The two rst authors contributed equally cerezolanlgov the development of the eld of geometric deep learning 7 Here the key insight was to note that the most success ful neural network architectures can be viewed as models with inductive biases that respect the underlying structure and symmetries of the domain over which they act The inductive bias refers to the fact that the model explores only a subset of the space of functions due to the assump tions imposed on its denition Geometric deep learning not only constitutes a unifying mathematical framework for studying neural network architectures but also provides guidelines to incorporate prior physical and geometrical knowledge into new architectures with better generaliza tion performance more ecient data requirements as well as favorable optimization landscapes 710 In this work we propose to import ideas from the eld of geometric deep learning to the realm of Quantum Machine Learning QML QML has recently emerged as a leading candidate to make practical use of nearterm quantum de vices 11 12 QML formally generalizes classical machine learning by embedding it into the formalism of quantum mechanics and quantum computation This formal gener alization can lead to practical speedups with the potential to signicantly outperform classical machine learning 13 since quantum computers can eciently manipulate infor mation stored in quantum states living in exponentially arXiv220502261v2 quantph 26 Sep 20222 large Hilbert spaces Similar to their classical counterparts the ability of QML models to solve a given task hinges on several fac tors with one of the most important being the choice of the model itself If the inductive biases 14 of a model are uninformed its expressibility is large leading to is sues such as barren plateaus in the training landscape 15 20 Adding sharp priors to the model narrows the eective search space enhancing its trainability and improving its generalization performance 2124 As such a great deal of eort has been recently put forward towards designing more problemspecic schemes with strong inductive bi ases 2533 Despite these eorts most architectures cur rently used in the literature remain problemagnostic as there is no overarching theoretical framework that provides guidelines for how to embed symmetries of the problem into the QML model The main contribution of this work is a series of Propo sitions Propositions 1 2 3 and 4 characterizing the land scape of possible quantum machine learning models that are invariant under a given symmetry group G By identi fying dierent types of strategies leading to group invariant models we pave the way for a more systematic and e cient symmetryinformed QML model design The power of our framework is showcased by applying it to classifying datasets based on purity timereversal dynamics multipar tite entanglement and graph isomorphism where we are able to recover in an eortless manner many celebrated quantum protocols and algorithms including very recent ones 3446 We also discuss the extension of our frame work to the design of equivariant quantum neural networks Finally we highlight the exciting outlook for the new eld of geometric quantum machine learning for which our ar ticle lays some of the groundwork II PRELIMINARIES Here we provide the background and denitions needed for our groupinvariant QML framework A Symmetry groups in supervised QML In this work we consider supervised binary classication tasks on quantum data We remark however that the methods derived here can be readily applied to more gen eral supervised learning scenarios or to unsupervised learn ing tasks In addition our work applies to classical data that has been encoded into quantum states For our purposes we consider the case where one is given repeated access to a set of labeled training data from a Figure 1 The role of inductive biases a In a quantum supervised learning task the goal is to train a parameterized model h to match the label predictions of an unknown func tion f The inductive biases represent the assumptions priors about our knowledge of how the inputs are related to the output predictions These are encoded in the way the model is built The goal of this work is to determine geometric priors from the underlying symmetries in the quantum data b Due to the biases in the model h explores only a subset of all possible functions dataset of the form S i yiN i1 Here i are nqubit quantum states from a data domain R in a ddimensional Hilbert space with d 2n while yi are binary labels from a label domain Y 0 1 The data in S is drawn iid from a distribution dened over RY and we assume that the labels associated to each quantum state are assigned according to some unknown function f R Y so that fi yi As shown in Fig 1a the goal is to train a parameterized model or hypothesis h to produce labels that match those of the target function f with high probability Here denotes the set of trainable parameters in the model For a given dataset a fundamental question to ask is what is the set of unitary operations on the states i that leave their respective labels yi unchanged Such set of op erations forms a group 47 G Ud a subset of Ud the unitary group of degree d In the following G is referred to as the symmetry group of the dataset Explicitly for every element V in G the label associated with any transformed state V iV is exactly the same as the label associated3 Figure 2 Group invariance in QML Consider a QML task of classifying singlequbit states according to their purity The symmetry group G of this task is the unitary group U2 as any unitary V U2 preserves the spectral properties of the data By imposing Ginvariance into the quantum model so that hV V h for all V U2 we can rediscover several known algorithms such as those listed in the gure with the original i Hence it is natural to require that the model we are training should produce labels that also remain invariant under the action of G on the data To capture such invariance we introduce the following deni tion Denition 1 Ginvariance A function h is Ginvariant i hV V h for all V G R 1 In principle such Ginvariance could be heuristically learnt by h via dataaugmentation 48 ie by includ ing additional training instances of the form V iV yi However such eort is undesirable for two main reasons First it obviously means an increased algorithmic runtime cost But second and most importantly such invariance learning is not guaranteed to be completely successful es pecially when G is large or continuous 7 Instead as shown in Fig 2 our main approach here is to design QML models h that are by construction Ginvariant for all To achieve this we introduce biases in the structure of h for instance by carefully choosing the architecture of the quantum neural network employed and the physical observable measured In the context of binary classication there are two main scenarios to consider In a rst scenario the data in both classes is invariant under a same symmetry group G and thus h needs to be invariant under this sole symmetry group In the second scenario the data in dierent classes have dierent symmetries and we denote as G0 and G1 the symmetry groups corresponding to data with labels yi 0 and yi 1 respectively In such case we have the freedom to consider QML models that are either G0invariant G1 invariant or both As shown below it is often convenient to build models that are invariant only under the action of one of the symmetry groups as this is sucient for data classication B Conventional and quantumenhanced experiments Thus far we have not dened what constitutes the pa rameterized model h This choice is tied to the physical resources one may have access to ie the way quantum data can be stored accessed and measured Since there is a large amount of freedom in this regard we nd it useful to restrict ourselves to two scenarios Following the de marcation proposed in 49 50 we consider two settings a conventional and a quantumenhanced one which are de ned as Denition 2 Conventional experiment In conventional experiments each data instance i is processed in a quan tum computer and measured individually Denition 3 Quantumenhanced experiment In quantumenhanced experiments multiple copies of each data instance i can be stored in a quantum memory and later simultaneously processed and measured in a quantum computer In both settings the model predictions are obtained from the quantum device experiment outcomes However as illustrated in Fig 3 the key dierence between the classical and quantumenhanced settings is that in the latter the QML model is allowed to act coherently on multiple copies of i This is in contrast with the conventional setting where the QML model can only operate over a single copy of i at a time C QML model structure Throughout this work we consider models consisting in a quantum neural network U ie a parameterized uni tary that can be realized on a quantum computer operat ing on k copies of an input state followed by a measure ment on the resulting state In other words we work with models belonging to the following hypothesis class Hypothesis Class 1 We dene the Hypothesis Class H1 as composed of functions of the form hk Tr UkU O 2 where k is the number of copies of the data state U is a quantum neural network and O is a Hermitian operator4 Figure 3 Conventional and quantumenhanced experiments a In a conventional experiment each data instance i in the dataset is sent to a quantum device The state obtained at the output of the quantum computation is measured with the measurement outcomes used to make predictions b In a quantumenhanced experiment a quantum memory allows us to store several copies of each state i in the dataset These copies can be simultaneously sent to a quantum device The state obtained at the output of the quantum computation is measured with the measurement outcomes used to make predictions For k 1 copies the models belonging to the Hypothesis Class H1 correspond to those that can be computed on a conventional experiment according to Denition 2 On the other hand k 2 copies lead to models in quantum enhanced experiment according to Denition 3 Arguably models from the Hypothesis Class 1 are not of the most general form For instance these could be ex tended to allow for nontrivial classical postprocessing of the measurement outcomes and also to involve more than one circuit or observable Still the Hypothesis Class 1 al ready encompasses most of the current QML frameworks 51 and can serve as a basis for more expressive QML models In the following we restrict our attention to mod els pertaining to H1 and leave the study of more general models for future work D Classication accuracy Let us dene some terminology that will allow us to assess the accuracy of a models classication First we remark that we do not consider precision issues when dis cussing classication accuracy Recall that the models pre dictions in Eq 2 are expectation values which in practice need to be estimated via measurements on a quantum com puter Hence given a nite number of shots measurement repetitions these can only be resolved up to some addi tive errors However for the sake of simplicity we here assume the limit of zero shot noise ie innite precision and we will challenge this assumption when appropriate in the results section With this remark in hand consider the following denitions of dierent degrees of classication accuracy Denition 4 Classication Accuracy i We say that a model provides no information that can classify the data if its outputs are always the same irrespective of the label associated to the input quantum state ii We say that a model performs noisy classication if its outputs are the same for some but not all data in dierent classes iii We say that a model perfectly classies the data if its outputs are never the same for data in dierent classes We note that in some cases a model can at best only perform noisy classication as its accuracy will be funda mentally limited by the distinguishability of the quantum states in the dataset Note that this is typically not an is sue for classical datasets although the issue does arise for noisy classical data In some cases for example as in the timereversal dataset that we consider below the quantum data states associated with dierent output labels are non orthogonal In this case perfect classication cannot be achieved regardless of the form of the model E Useful denitions In this rather mathematical section we present de nitions that will be used throughout the main text For further reading we refer to 52 53 While G describes the symmetries in the data it will be crucial to characterize the symmetries of G itself The symmetries of a group are captured by the commutant CG W Cdd W V 0 V G 3 which is the vector space of all dd complex matrices that commute with G More generally one can also consider the space of matrices in Cdkdk commuting with the kth power tensor of the elements in G 545 Denition 5 kth order symmetries Given a unitary representation G Ud of a group its kth order symme tries are CkG W Cdkdk W V k 0 V G 4 for all positive integers k Firstorder symmetries k 1 are known as the linear symmetries while second order ones k 2 are known as quadratic symmetries of G In general there may be kth order symmetries that are not Hermitian and thus not physical observables However as proved in Appendix A any matrix in CkG has nonzero projection into the Her mitian subspace of CkG Hence one can always asso ciate any nonHermitian element in CkG to a Hermitian one that also belongs in CkG While the kth order symmetries can be dened for any group in the case when G is a Lie group there exists addi tional structure that one can exploit In particular there exists an associated Lie algebra g ud such that eg G That is g g ud eg G Here ud denotes the set of d d skewsymmetric matrices We also nd it con venient to introduce the following denition Denition 6 Orthogonal complement Given a Lie al gebra g ud its orthogonal complement with respect to the HilbertSchmidt norm is dened as g h ud Tr hg 0 g g 5 Note that g is not a Lie algebra III GENERAL RESULTS FOR GINVARIANCE In this section we determine conditions leading to models that are Ginvariant by design These results are stated in a general problemagnostic way and will be applied to specic datasets in Secs IV and V A A single symmetry group Let us rst consider the case when there is a single sym metry group G associated with all the instances in the dataset We aim at nding models hk from Hypothe sis Class H1 that are Ginvariant ie models such that hk V V hk for all V G and choice of parame ters Dening O U OU 6 so that hk Tr k O we explicitly have hk V V Tr V kkV k O 7 Evidently the model will be invariant under G if O V k 0 for all V G Thus the following propo sition holds Proposition 1 Let hk H1 be a model in Hypothesis Class 1 and G be the symmetry group associated with the dataset The model will be Ginvariant if O CkG Proof The proof of this proposition follows from Deni tion 5 If O belongs to the vector space of the kth order symmetries CkG then O V k 0 and thus hk V V hk for all V G Furthermore as previously discussed we can guarantee that O in Proposition 1 can always be taken as a Her mitian operator and thus as an observable Complementary to Proposition 1 we now prescribe a sec ond way of ensuring Ginvariance of the model when G forms a Lie group This is achieved when the operator O can be taken orthogonal to V V k for all V in G and for all in S We formalize this statement in the following proposition proved in Appendix B Proposition 2 Let hk H1 be a model in Hypothesis Class 1 Then let G be the symmetry Lie group associated with the dataset and let g ud be its Lie algebra with i11 g The model will be Ginvariant when ig and O spanAj Ajj Here Aj ig an element of the orthogonal complement of g is a Hermitian operator acting on the jth copy of and Aj is an operator acting on all copies of but the jth one Note that in Proposition 2 we have assumed that i11 g where 11 denotes the d d identity matrix However it could happen that i11 is in g instead In this case the proposition will hold if ig and Aj ig as needs to have support on a vector space containing the identity B Multiple symmetry groups Let us now consider the case when each of the two classes in the dataset have a dierent symmetry group associated to them which we denote as G0 and G1 The concepts used in the previous section to obtain groupinvariant models ie commutant and orthogonal complement can also be leveraged to derive conditions under which a model hk is6 G0invariant G1invariant or both The following propo sition proved in Appendix C generalizes Proposition 1 to the case of two symmetry groups Proposition 3 Let hk H1 be a model in Hypothe sis Class 1 and let G0 and G1 be the symmetry groups associated with the dataset The model will be G0 and G1invariant if O CkG0 and O CkG1 In addition the model will be G0invariant but not necessarily G1invariant if O CkG0 but O CkG1 Conversely while not stated explicitly in Proposition 3 the model will be G1invariant but not necessarily G0 invariant if O CkG1 but O CkG0 Additionally when G0 and G1 are Lie groups with as sociated Lie algebras g0 and g1 we can generalize Propo sition 2 to the case of two symmetry groups Then the following proposition proved in Appendix C holds Proposition 4 Let hk H1 be a model in Hypothesis Class 1 and let G0 and G1 be the symmetry Lie groups associated with the dataset with g0 and g1 their respec tive Lie algebras with i11 g0 g1 The model will be G0 invariant and G1invariant when ig0 ig1 and when O spanAj Ajj Here Aj ig 0 ig 1 is a Her mitian operator acting on the jth copy of Aj is an oper ator acting on all copies of but the jth one In addition the model will be G01invariant but not necessarily G10 invariant when ig0 igi and Aj ig 0 but Aj ig 1 In Proposition 4 we have assumed that i11 belongs to g0 and g1 However if i11 instead belongs to g i with i 0 1 then the proposition will hold by replacing gi by g i and conversely Propositions 14 provide conditions under which one can guarantee that a QML model in Hypothesis Class 1 is G invariant While the results presented in this section are valid for the case when there are two symmetry groups the previous propositions can be readily extended to more general scenarios such as multiclass classication where one has a set Gii of symmetry groups For instance one could generalize Proposition 3 to show that a model will be invariant under all symmetry groups Gi if O CkGi for all i IV LIE GROUPINVARIANT MODELS We now apply the general results presented in the pre vious section to identify Ginvariant models that can clas sify states originating from several paradigmatic quantum datasets whose invariances are captured by Lie groups These include the purity dataset Sec IV A the time reversal dataset Sec IV B and the multipartite entan glement dataset Sec IV C Our results are stated in the form of theorems For pedagogical reasons we include in the main text the proofs for most of these theorems as they provide a constructive introduction to our framework A Purity dataset As a rst application we consider the QML task of clas sifying nqubit states according to their purity 49 Given a dataset S i yiN i1 we want to discriminate those i that are pure from those that are not That is we assign labels yi 1 if Tr 2 i 1 0 if Tr 2 i b 1 8 to states i according to values of their purities Tr 2 i The symmetry group G associated with the data in both classes is the group of unitaries Ud This follows from the fact that unitaries preserve the spectral properties of quantum states and thus their purity remain unchanged under the action of Ud 1 Conventional experiments Let us rst consider the case of conventional experiments see Denition 2 ie when the model h1 in Eq 2 has access to k 1 copy of each data at a time For such a case we can derive the following theorem Theorem 1 Let h1 H1 be a model in Hypothesis Class 1 computable in a conventional experiment There exists no quantum neural network U and operator O such that h1 is invariant under the action of Ud and can classify ie provide any relevant information about the data in the purity dataset Proof The strategy of this proof is as follows First we identify the possible Ginvariant models arising from Propositions 1 and 2 Then we show that these mod els cannot be used to perform classication for the purity dataset Finally we prove that no other Ginvariant model within H1 with k 1 copies exist Recall from Proposition 1 that a model is Ginvariant under Ud if O is in the commutant of Ud Since G Ud is irreducible 55 in Cdd we know from Schurs Lemma 52 that CG span11 97 It follows that if O is in CG it takes the form O 11 Moreover we impose R to ensure the Hermiticity of O This yields a constant model prediction h1 for any Hence the Ginvariant models of Proposition 1 do not provide any information about the purity of a state and thus cannot classify the data Let us now analyze the models arising from Proposi tion 2 Since g ud we have g 0 10 where 0 denotes the d d null matrix Hence if O ig then h1 0 for any This shows that the G invariant models arising from Proposition 2 do not provide any information about the purity of a state and cannot classify the data So far we have seen that Ginvariant models obtained by applying Propositions 1 and 2 do not allow for classication of the purity dataset Still this does not preclude the ex istence of other Ginvariant models within H1 that may be adequate for classication However we now prove that no other Ginvariant models exist beyond those already con sidered Given that h1 V V h1 should be true for any unitary V in Ud the latter also needs to hold when uniformly averaging h1 V V over all possible V in G Namely we require that EGh1 V V h1 The lefthandside of the equality is evaluated as EGh1 V V Ud dV Tr UV V U O Tr Ud dV UV UV O Tr Ud dV V V O Tr TrO d 11 where the integral denotes the Haar average over the uni tary group In the second equality we have used the linear ity of the trace and of the integral Then in the third equal ity we have used the leftinvariance of the Haarmeasure Finally in the fourth equality we have explicitly computed the integration via the Weingarten calculus 56 57 From Eq 11 we can see that the only way for h1 to be equal to Tr TrO for general quantum states is to have O 11d or O 0 which leads to the solutions given by Propositions 1 and 2 Hence we have shown that there are no models in the Hypothesis Class 1 that are Ginvariant under the action of Ud and that can classify the data in the purity dataset as they all provide no information according to Denition 4 The previous proposition shows that one cannot classify the data in the purity dataset with a model in H1 operating in a conventional experiment In hindsight one could have foreseen this result Indeed computing the purity requires evaluating a polynomial of order two in the matrix ele ments of and thus the linear functions as the ones here considered are deemed to fail From a QML perspective h1 is ultimately a linear classier where the parameter ized quantum neural network U denes a hyperplane such that the expectation value of O is positive for one class and negative for the other However the manifolds of quantum states with dierent purities are not linearly sep arable in the state space This can be better exemplied by singlequbit states in the Bloch sphere where no plane can be drawn across the sphere which linearly separates pure and mixed states In the spirit of kernel tricks 58 one can introduce non linearities by allowing the models hk to coherently ac cess multiple copies of This is precisely the setting of quantumenhanced experiments which we now explore 2 Quantumenhanced experiments We now consider the case of quantumenhanced experi ments see Denition 3 where multiple copies of a state in the dataset can be operated over in a coherent manner As we now see k 2 copies is already enough for classifying states according to their purity Theorem 2 Let h2 H1 be a model in Hypothesis Class 1 computable in a quantumenhanced experiment There always exists quantum neural networks U and op erators O resulting in O span1111 SWAP such that h2 is invariant under the action of Ud If the model has nonzero component in SWAP it can perfectly clas sify the data in the purity dataset The special choice of O SWAP leads to h2 Tr 2 Proof Recall from Proposition 1 that a model h2 in the Hypothesis Class 1 is Ginvariant if O is a quadratic symmetry of Ud ie if for all V Ud V 2 OV 2 O 12 From the SchurWeyl duality 59 we know that the kth order symmetries of Ud are given by CkUd span Sk 138 Figure 4 Elements of the Symmetric group The Sym metric group Sk is composed of the k distinct permutations over k indices Here we illustrate its representation acting on tensor product systems for the cases of k 1 2 and 3 copies of nqubit states each represented as a line For example the element SWAP 11 S3 depicted second from lefttoright acts on a tensor product state as SWAP 11 1 2 3 2 1 3 with Sk the representation of the Symmetric Group that acts by permuting subsystems of the kfold tensor product of the input state depicted in Fig 4 As shown in Fig 4 for the case of k 2 copies this group contains only two elements 60 S2 11 11 SWAP 14 with 11 11 the identity acting on each of the two copies of and SWAP the operator swapping these copies As a consequence h2 can be made Ginvariant under the action of Ud when O a1 11 11 a2 SWAP with a1 a2 R The latter is diagrammatically presented in Fig 5 This yields predictions h2 a1 a2 Tr 2 15 showing that the model will be able to perfectly classify the states in the purity dataset according to Denition 4 for any choice of a2 0 We now make several remarks regarding the results in Theorem 2 and regarding our framework in general First we note that while Proposition 1 provides a straightfor ward guideline to obtain Ginvariant models it does not prescribe how to actually build the quantum neural net works U and the measurement operators O ensuring that O U OU is a kth order symmetry All that we know is the specic form that the resulting O needs to have Thus it is still necessary to nd an ad equate ansatz for U and an appropriate observable O that can be eciently measured For instance it is clear Figure 5 Quadratic symmetries for G Ud a A model h2 is Ginvariant when O is a quadratic symmetry of G that is when V 2 OV 2 O for all V G This equality is shown in diagrammatic tensor representation where each line corresponds to a ddimensional Hilbert space hosting a copy of and boxes represent unitary operations b For V Ud we have V V V V 11 depicted on the left part Furthermore we know that the quadratic symmetries of Ud are spanned by the identity 11 11 and the SWAP operators We depict these on the right c Using the diagrammatic tensor representation we verify that V 2 OV 2 O for the case when O SWAP that simply choosing U 1111 and O SWAP sat ises the conditions of Theorem 2 This has the issue that one cannot eciently estimate the expectation value of the SWAP operator its Pauli decomposition has a number of terms that scales exponentially with n using a model such as h2 However it is well known that by adding an ancilla qubit and by using the Hadamardtest 34 one can eciently estimate the expectation value of the SWAP op erator In Appendix D we show how our present formalism can be applied to models that include an ancillary qubit Surprisingly the latter allows us to discover a new con nection between the Swap Test 34 and the ancilla based algorithm of Ref 61 B Timereversal dataset In this section we are interested in classifying states ac cording to whether they are obtained from a timereversal symmetric 62 dynamic or from an arbitrary one That is the states i of the corresponding dataset S i yiN i19 now have labels yi 1 if i is real valued 0 if i is Haar random 16 Specically the states in the dataset have a label yi 1 if they are generated by evolving some xed realvalued duciary state with a timereversalsymmetric unitary and thus are realvalued too and a label yi 0 if they are generated by evolving the same reference state with a Haar random unitary In contrast to the case of the purity dataset previously considered one can now associate a distinct symmetry group to each of the two classes On one hand the states with label yi 0 have G0 Ud as a symmetry group On the other hand the states with label yi 1 have as a symmetry group G1 Od which is the orthogonal Lie group of degree d This is because the unitaries in Od pre serve the timereversal symmetry of the states and thus their label For convenience we recall that Od is the group of d d orthogonal matrices That is V Od V V t V tV 11 This group can be obtained by exponentia tion of the orthogonal Lie algebra which consists of d d skewsymmetric matrices g1 od ie Od eod Moreover the unitary Lie algebra g0 ud can be split as ud od uCd Here note that od corresponds to the purely realvalued subspace of the unitary algebra Its orthogonal complement g 1 uCd 17 corresponds to the purely imaginary subspace of the uni tary Lie algebra Having two symmetry classes allows for the design of a new classication strategy Namely one can classify the data using a G1invariant model but not G0invariant hk such that hk i c if yi 1 hk i b1 b2 if yi 0 18 with c b1 and b2 real values determined by the measure ment operator and the states in the dataset If c b1 b2 then Eq 18 suces for perfect classication according to Denition 4 If c b1 b2 we can still use Eq 18 for noisy classication see Denition 4 but there could be a chance of misclassication as one cannot perfectly distin guish between states in dierent classes yielding the same prediction Such misclassication events will remain un likely as long as the probability that hk i c up to some additive error is small for states with label yi 0 In Appendix E we present a Lemma that formalizes the previous statement In any case for now we assume that a model satisfying Eq 18 can classify the data in the dataset with probability high enough and will challenge this assumption in due course 1 Conventional experiments For the case of conventional experiments ie k 1 copies in Eq 2 the results in Proposition 3 cannot be used to nd G1invariant models classifying the time reversal dataset Indeed since the representation of G1 Od is irreducible using Schurs Lemma 52 we know that CG1 span11 19 ie G1 has no nontrivial linear symmetries that could be exploited for the purpose of classication Still we can use Proposition 4 to nd group invariant models First we note that the input states i belong to g 1 uCd when they are timereversalsymmetric but to g0 ud when they are Haar random Hence h1 will be invariant under the action of G1 but not necessarily invariant under the action of G0 if O is in ig1 but not in ig 0 This is formalized below Theorem 3 Let h1 H1 be a model in Hypothesis Class 1 computable in a conventional experiment There always exist realvalued quantum neural networks U and operators O resulting in O iod with O 0 such that h1 is invariant under the action of Od and can perform noisy classication of the data in the time reversal dataset Proof We aim at nding models that are G1invariant with G1 Od but not necessarily G0invariant with G0 Ud distinguishing timereversalsymmetric states from Haar random ones According to Proposition 4 the model will be G1invariant but not G0invariant if O ig1 iod and O 0 eg if O is a purely imaginary operator Now lets show that there is a choice of O and U allowing for classication Taking O ig1 and U G1 Od the resulting O is also contained in ig1 since a Lie algebra is closed under the action of its associated Lie group Because timereversalsymmetric states i are exclusively contained in ig 1 it follows from Eq 5 that h1 i 0 i with label yi 1 Moreover the previous equation is not satised for Haar random states as these will generally have both real and10 complex parts As such h1 i will not necessarily be zero for states with label yi 0 Hence the model satises Eq 18 such that it can perform noisy classication ac cording to Denition 4 for the states in the timereversal dataset So far we have identied models that yield predicted val ues of 0 for timereversalsymmetric states but yield values in a continuous range for states drawn from the Haar dis tribution As such when taking into account noise in the prediction of the model any nontimereversal state with prediction values close to zero may be misclassied In fact as proven in Appendix F Haar random states lead to prediction values that with probability close to one lie in a range that becomes exponentially concentrated around zero with the number of qubits n In turn it can be shown that to classify states in the dataset with a success proba bility of at least 23 one would need to repeat the experi ment a number of times that scales as 22n7 49 50 63 This raises attention towards a practical aspect in the design of QML models that we have not previously consid ered the scaling in the number of experiment repetitions required for accurate classication Our framework allows us to identify Ginvariant models but we are not guaran teed that such models are practical for large system sizes n In fact we have seen that an exponential number of repetitions are needed to make practical use of the models in Theorem 3 This motivates us to further continue the search of Ginvariant models in quantumenhanced exper iments in the hope that these might avoid the exponential scaling present in conventional experiments 2 Quantumenhanced experiments For quantumenhanced experiments ie k 2 copies in Eq 2 we can show that the following theorem holds Theorem 4 Let h2 H1 be a model in Hypothesis Class 1 computable in a quantumenhanced experiment There always exist quantum neural networks U and op erators O resulting in O with the Bell state on 2n qubits such that h2 is invariant under the action of Od and can perform noisy classication of the data in the timereversal dataset Proof We aim at nding models that are invariant under Od but not under Ud According to Proposition 3 this can be achieved by ensuring that O is a quadratic symmetry of Od but not of Ud From the SchurWeyl Figure 6 Elements of the Brauer algebra A basis for the Brauer algebra Bk is composed of 2k2kk possible pairings on a set of 2k elements where any element may be matched to another Here we illustrate its representation acting on tensor product systems for the cases of k 1 2 and 3 copies duality we know that the kth order symmetries of Od are given by the Brauer algebra Bk 64 CkOd Bk 20 The elements of Bk are depicted in Fig 6 As shown in Fig 7 for k 2 the Brauer algebra is spanned by three elements B2 span 11 11 SWAP 21 where denotes the Bell state on 2n qubits 1 d d j1 j j 22 It can be veried that is indeed a quadratic sym metry for Od To see that recall the ricochet property also called the transpose trick which states that for any linear operator A acting on a ddimensional Hilbert space A 11 11 At 23 Using Eq 23 one can assert that V t2 V 2 11V tV 11V tV and hence that C2Od see also Fig 7b for a diagram matic proof11 Figure 7 Quadratic symmetries for G Od a We know that any V Od is such that V V t V tV 11 We schematically show this fundamental property on the left We know that the quadratic symmetries of Od are elements of the Brauer algebra B2 whose basis contains three elements the identity 11 11 the SWAP operator and the projector onto the Bell state We depict these on the right c Using the diagrammatic tensor representation we verify that V t2 OV 2 O For the case of we use the ricochet property of Eq 23 The only element that is in C2Od but not in C2Ud is the projector onto the Bell state Hence according to Proposition 3 h2 is Odinvariant if O with R Now the model is such that h2 i 2 i In Fig 8a we show a circuit that could be used to measure this overlap Recall that the timereversal states i are obtained by evolving a realvalued duciary state taken to be 0n without loss of generality under a unitary in Od One can verify that if O then h2 i 02n2 1 d2 24 for all i with labels yi 1 On the other hand the model output will not be constant for states with labels yi 0 ie for states obtained by evolving 0n under a Haar random unitary Wi In this case one has h2 i Wi Wi02n 2 25 which depends on the choice of Wi Overall we have shown that choosing O leads to a model invariant under Od that satises Eq 18 and hence that can perform noisy classication according to Denition 4 of the states in the timereversal dataset Figure 8 Circuits used in quantumenhanced experi ments a When classifying timereversal states the dataset is composed of states i obtained by evolving a duciary real valued state with an orthogonal unitary or with a Haar random unitary b When classifying timereversalsymmetric dynam ics the dataset is composed of orthogonal and Haar random unitaries Wi Here we are free to choose the 2nqubit initial state in that will be evolved under the action of W 2 i In both panels we have indicated with a red dashed box the circuit for implementing a Bellbasis measurement In particular an allzero measurement outcome corresponds to the probability of measuring Theorem 4 shows that measuring the Bell state allows us to do classication However this does not solve the scaling issue discussed earlier Indeed as proven in Appendix F the predictions values of the model given in Eq 25 still concentrate exponentially close to zero as a function of the number of qubits This implies that we still need an ex ponential number of experiment repetitions to accurately classify the data However as we now show this problem can be overcome if we slightly modify the task at hand from the classication of timereversalsymmetric states to the classication of timereversalsymmetric dynamics For this new task rather than being given states we assume instead access to the unitaries used to produce these states The corresponding dataset has the form Wi yiN i1 with yi 1 if Wi Od 0 if Wi Ud 26 which has the same two symmetry groups G1 Od and G0 Ud as before As shown in Fig 8b the main advantage of this sce nario is that we are now allowed to initialize the 2nqubit register to any global state in and to simultaneously evolve the rst and the second n qubits according to the same unitary Wi To capture this additional freedom we consider models in a new hypothesis class dened as Hypothesis Class 2 We dene the Hypothesis Class H2 computable in a quantumenhanced experiment as com12 posed of functions of the form hW Tr UW 2 inin W 2U O 27 where U is quantum neural network acting on the 2n qubits O is a Hermitian operator and in is an initial state on 2n qubits In this context we can still use Proposition 3 to show that the following theorem holds Theorem 5 Let h H2 be a model in Hypothesis Class 2 computable in a quantumenhanced experiment There always exist quantum neural networks U and op erators O resulting in O with being the Bell state on 2n qubits such that h is Odinvariant but not Udinvariant that can perfectly classify the dy namics in the timereversal dataset The special choice of in recovers the algorithm for classifying time reversalsymmetric dynamics presented in 49 Proof Recall from Proposition 3 that h is invariant under Od but not under Ud if O is in C2Od but not in C2Ud Following the proof of Theorem 4 we know that this can be achieved with the choice of O Moreover a straightforward calculation shows that if we choose in we have hWi 1 Wi with label yi 1 28 recovering the algorithm in 49 On the other hand hWi is Widependent and will concentrate around zero if yi 0 see Appendix This means that the model out puts a value of 1 if the unitary has label yi 1 and outputs a value of 0 with high probability if the unitary has la bel yi 0 Thus the models in Hypothesis Class 2 can perform perfect classication according to Denition 4 of timereversalsymmetric dynamics As shown in the proof of Theorem 5 now the model gives nonoverlapping predictions for the data in dierent classes meaning that we can now perform classication with O1 experiment repetitions This is in contrast to the model dened in Theorem 4 which requires an expo nential number of experiments for accurate classication This illustrates how QML models capable of achieving a quantum advantage naturally emerge in our framework as Ginvariant models C Multipartite entanglement dataset In this section we consider the more involved task of classifying pure quantum states according to the amount of multipartite entanglement they possess Entanglement has been shown to be a fundamental resource 65 66 in quantum information quantum computation and quantum sensing 6775 Hence its study and characterization is quintessential for quantum sciences Here we recall that entanglement is relatively well un derstood for bipartite pure quantum states eg via the Schmidt decomposition for pure states 76 and that groupinvariance arguments have been previously used to characterize entanglement in bipartite mixed states 77 78 However the same cannot be said for the multipar tite entanglement 7982 In this case the entanglement complexity scales exponentially with the number of par ties and there is no unique measure to quantify it Thus we employ our framework to not only obtain Ginvariant QML models that can accurately classify multipartite en tangled states but also to better understand the unique nature of multipartite entanglement In this context we also recall that the presence of publicly available datasets such as the NTangled dataset 83 composed of quantum states with varying amounts of multipartite entanglement makes this an extremely rich application for our framework and for benchmarking QML models Let E be a multipartite entanglement measure satisfying E 0 1 with E 0 if the state is separable and E 0 if the state contains multipartite entanglement between the n qubits for instance see the entanglement measures in Refs 36 8486 The multipartite entangle ment dataset is of the form S i yiN i1 where yi 1 if Ei b 0 0 if Ei 0 29 Here the symmetry group G associated with the data in both classes is the Lie group G n j1 U2 with an associated Lie algebra g n j1 su2 This is due to the fact that local unitaries n j1 Vj do not change the multipartite entanglement in a quantum state 1 Conventional experiments Since computing the entanglement typically requires evaluating a nonlinear function of the quantum state 65 it is expected that models in conventional experiments will not be able to classify the states in this dataset This in tuition can be conrmed with the following theorem Theorem 6 Let h1 H1 be a model in Hypothesis Class 1 computable in a conventional experiment There exists no quantum neural network U and operator O such that h1 is invariant under the action of n j1 U213 and can classify ie provide any relevant information about the data in the multipartite entanglement dataset Proof First let us verify that Propositions 1 and 2 do not yield any adequate model for classication purposes To identify the linear symmetries of G required for the appli cation of Proposition 1 we apply the Commutation The orem for tensor products 87 88 which states that the commutant of a tensor product of operators is the tensor product of the commutants of each operator Hence CG span 11n 2 30 where 112 denotes the 2 2 identity This results in the choice O 11 R and constant model predictions i h1 i that cannot distinguish between states Additionally one can verify that the orthogonal comple ment of g is trivial g 0n 2 31 with 02 the 2 2 null matrix such that models designed under Proposition 2 would also result in uninformative con stant value predictions Hence using Propositions 1 and 2 to obtain Ginvariant models from Hypothesis Class 1 with k 1 will lead to trivial models that cannot classify the states in the mul tipartite entanglement dataset Following a similar argu ment as the one developed in the last part of the proof of Theorem 1 one can also verify that no other Ginvariant models exist with k 1 Indeed if h1 V V is invari ant for any V d j1 Vj it also has to be invariant when uniformly averaged over every Vj in U2 Performing this averaging we obtain EG h1 V V Tr TrO d 32 for V d j1 Vj The only way for h1 to be equal to Tr TrOd for any state is to have O 11d or O 0 that is solutions already covered by Propositions 1 and 2 2 Quantumenhanced experiments Let us rst consider the case of k 2 copies in Eq 2 We can show that the following theorem holds Theorem 7 Let h2 H1 be a model in Hypoth esis Class 1 computable in a quantumenhanced ex periment There always exist quantum neural net works U and operators O resulting in O span n j111j 4 SWAP j such that h2 is invariant under the action of n j1 U2 and can perfectly classify the data in the multipartite entanglement dataset Here 11j 4 denotes the 4 4 identity matrix on the jth qubit of each copy of and SWAP j denotes the operator that swaps the jth qubits of each copy of There exist special choices of O which recover all the multipartite entangle ment measures proposed in Refs 3642 Proof From Proposition 1 we know that h2 will be G invariant if O is a quadratic symmetry of G Here we can again invoke the Commutation Theorem for ten sor products to obtain the space of these symmetries C2G span n j1 11j 4 SWAP j 33 where 11j 4 denotes the 4 4 identity matrix acting on the jth qubit of each of the two copies of and where SWAP j denotes the operator that swaps the jth qubits of the copies of Note that C2G is spanned by 2n elements meaning that there exists an exponentially large freedom in choosing O Evidently some choices of O will not be useful for characterizing multipartite entangle ment For instance O n j1 11j 4 leads to trivial models predictions h2 Tr 2 1 for any state Similarly O n j1 SWAP j SWAP leads to h2 Tr 2SWAP Tr 2 1 On the other hand there are choices for O that can indeed characterize entanglement For instance O 2 11 SWAP j 11j 34 with 11j the identity on all qubits but the jth ones leads to h2 21 Tr 2 j which is the impurity of j Trj ie the impurity of the reduced state on the jqubit and a bipartite entanglement measure across the cut jth qubit rest Averaging over each of the n qubits ie O 2 n n j1 11 SWAP j 11j 35 recovers the multipartite entanglement measures of 37 38 Notably the result in Eq 34 can be further generalized as follows First let us dene S 1 2 n as the set of integers indexing each qubit and let PS be its power set ie the set of subsets of S with cardinality PS 2n14 Dening the operator O 2 11 jQ SWAP j 11j 36 for any Q PS leads to the generalized version of the Concurrence measure for multipartite pure states in 39 40 Even more generally for any choice of Q the operator O 11 1 2Q jQ 11j 4 SWAP j 11Q 37 where Q SQ leads to the Concentratable Entangle ment family of multipartite entanglement measures intro duced in 36 see Proposition 3 in 36 where the special case Q S also leads to the measure of 41 On the other hand O 11 1 2n n j1 11j 4 SWAP j 38 leads to the ntangle measure 42 see Proposition 5 in 36 Since several of the previous choices for O lead to en tanglement monotones the models output will be dierent for data in dierent classes Hence one can perfectly clas sify the data in the multipartite entanglement dataset The results in Theorem 7 showcase how Propositions 14 can lead to extremely powerful and nontrivial results By simply imposing the Ginvariance condition on the model one is able to naturally nd an exponentially large man ifold of solutions capable of classifying the states in the multipartite entanglement dataset The latter leads to the intriguing possibility that C2G contains solutions lead ing to new entanglement measures Going further one could also investigate the potential of models acting on more than k 2 copies a prospect that has been largely unexplored Here we know from Propo sitions 1 that if O is a kth order symmetry then the model hk is Ginvariant under the action of n j1 U2 Combining Eq 13 and the Commutation Theorem leads to CkG span n j1 Sj k 39 where Sj k denotes the Symmetric group acting on the k copies of the jth qubit Since the dimension of CkG scales as kn ie exponentially with k the manifold of Ginvariant models is likely to lead to a rich variety of entanglement measures V DISCRETE GROUPINVARIANT MODELS In the previous section we focused solely on situations where the symmetry group associated with the dataset was a unitary representation of some compact Lie group Still our formalism can be equally applied in the case of rep resentations of discrete groups Discrete groups are the relevant mathematical structure for instance when the quantum data is invariant under a nite set of permuta tions This covers cases involving spatial invariance of con densed matter states on a lattice or structural invariances in states of molecular systems To illustrate such potential applications we now address the task of classifying states belonging to a dataset with symmetry group G Sn ie the Symmetric group consisting of all the n permutations over a set of n indices A Graph isomorphism dataset In this section we consider a dataset related to the so called graph isomorphism problem where the goal is to determine if two graphs are isomorphic This classication task has a rich history in computational sciences 89 and is known to be in the NP complexity class although it has not been shown to be NPcomplete To solve this problem several classical algorithms with quasipolyno mial complexity in the graph size 90 and also quantum heuristics 4346 have been proposed When using a quan tum model for graph classication purposes the rst step is to encode graphs onto quantum states Here we take such encoding to be xed and start by detailing how it is performed and how the graph isomorphism dataset is generated Recall that a graph is specied as G V E where V is a collection of n nodes and E is a collection of edges Two graphs G and G are said to be isomorphic and denoted as G G if there exists a bijection between the sets of edges belonging to G and G To build the dataset we x two reference nonisomorphic graphs G0 and G1 G0 G1 and generate graphs Gi that are isomorphic to either G0 or G1 To each of these graphs we assign labels yi 0 or yi 1 if it is isomorphic to G0 or G1 respectively Next we encode these graphs Gi into quantum states i This is achieved by evolving an initial Sninvariant duciary state in eg in n as i WGiinW Gi 40 where WGi eitHGi Here t 0 is a xed evolution time chosen such that the action of WG0 and WG1 over in is dierent and HGi is an Hamiltonian whose15 Figure 9 Permutation invariance in the graph isomor phism dataset Consider the state representing a quantum system of nspins interacting under some Hamiltonian that fol lows the topology of an underlying graph G By conjugating the state with an element P Sn one obtains a new quantum state PP whose interaction graph G is isomorphic to G That is and PP have the same label in the dataset topology is that of the graph Gi Specically we take it to be dened as HGi jjEi ZjZj jVi Xj 41 with Zj and Xj denoting the Pauli Z and X operators act ing on qubit j respectively We note that there exists more general ways to encode and process graph information in quantum states In particular the quantum graph convo lutional neural network introduced in Ref 32 generalizes the unitary WGi used here and is specically tailored to represent quantum systems that have a graph structure see Appendix G for a detailed description Taken together the graph generation and the encoding in Equation 40 allow us to dene the graph isomorphism dataset as a collection S i yiN i1 of states i with labels yi 1 if Gi G1 0 if Gi G0 42 As shown in Fig 9 the states i can be thought as rep resenting an nqubit quantum system whose interaction topology follows that of a graph Gi The symmetry group G associated with both classes in the dataset is the Symmet ric group Sn as one can map states within the same class via the action of elements in Sn see Fig 9 Explicitly let P be an operator in Sn and dene the state i PiP which can be expressed as i PWGiinW GiP Us ing the fact that PeitHGiP eitHG i for a Hamil tonian HG i PHGiP with G i Gi we have i WG iPinPW G i Since in is Sninvariant then PinP in and given that G i Gi we conclude that the state i WG iinW G i shares the same label as i Having dened the dataset of interest we proceed to show that models in conventional experiments suce to classify the data Theorem 8 Let h1 H1 be a model in Hypothesis Class 1 computable in a conventional experiment There always exist quantum neural networks U and operators O resulting in O spanAn with A in U2 such that h1 is invariant under the action of Sn Proof From Proposition 1 we know that h1 will be in variant under the action of Sn if O is a linear symmetry of Sn Using the SchurWeyl duality leads to 91 CSn spanAn A U2 43 meaning that the operator O has to be a Hermitian linear combination of nfold tensor products of singlequbit unitaries Notably the dimension of this solution manifold grows polynomially with n as the dimension of CSn can be shown to follow the Tetrahedral numbers Finally it remains to identify an adequate O among the space of operators that was just dened This choice should be taken such that the model predictions are maxi mally distinct for states belonging to dierent classes that is h1 i h1 i if yi yi For an adequate param eterization of O this search could be turned into an optimization task Given that by construction the model predicts the same value for any states i belonging to the same class this optimization would only require a single representative state for each class Otherwise one could employ heuristicallydened or physicallymotivated oper ators In particular we highlight that the operators studied in 4346 to distinguish nonisomorphic graphs belong to the family of O yielded by Theorem 8 Overall Theorem 8 examplies how our present frame work can be readily applied to datasets with discrete sym metries While studied here for the case of G Sn this can be specialized to subgroups of Sn such as the group of reexions translations or more subtle discrete symme tries which naturally arise in condensedmatter models and quantum chemistry problems VI EQUIVARIANT QUANTUM NEURAL NETWORKS While the framework laid here provides the ultimate form that a Ginvariant model h should adopt it does neither prescribe how to actually parameterize the quan tum neural networks U nor tell us how to choose the16 measurement operator O that realizes O U OU such that it complies with our theorems For this purpose it is convenient to consider the action of the quantum neural network and the measurement process separately and note that these can be generally though as concatenated maps More generally a constructive way to achieve Ginvariance of general QML models starts by decomposing the model as h EM M E1 1 44 ie as a composition of M maps Em m with integer labels m 1 M each parameterized by a subset of parame ters m For instance one such map could represent the action of a QNN or of its individual constituents ie its layers the nal measurement operation steps of post processing or even the process of encoding classical data into quantum states in the rst place Although imposing invariance at the map level eec tively results in global invariance of the model this is quite restrictive A more relaxed approach towards the construc tion of group invariant models involves the concept of equiv ariance 79 92 which is now dened Denition 7 Gequivariance Given a group G with an action on spaces A and B a function E A B is called Gequivariant if it commutes with the action of the group EV x V Ex 45 for all elements V G and inputs x A That is a function is Gequivariant if groupshifting the input x V x produces a groupshifted output Ex V Ex It can be veried that i Gequivariance of the intermediary maps m M along with ii Ginvariance of the nal map m M is sucient to ensure Ginvariance of the composed model Intuitively equivariance permits the propagation of the action of elements of G up to the nal map so that the symmetries get preserved Accordingly a model h belonging to Hypothesis Class 1 could be split in terms of the transformation of the in put state and the nal measurement That is h E2 E1 with E1 UkU and E2 Tr Ok Thus the model h will be Ginvariant if E2 is invariant and E1 is equivariant As before invariance of E2 can be achieved by choosing the measurement op erator O to be a Hermitian operator satisfying one of the Propositions 14 On the other hand equivariance of E1 can be achieved in a way very close in essence to Propo sition 1 Specializing Denition 7 to the case of unitary maps acting on k copies of we see that equivariance of such QNN or of its layers is equivalent to requiring that U V k 0 V G 46 That is a unitary U is Gequivariant if U CkG it belongs to the kth commutant of G For instance for graph classication the quantum graph convolutional neural network presented in Appendix G can be veried to be be equivariant under the action of Sn Overall approaching Ginvariance through the decom position in Eq 44 has the advantage of modularity equivariant maps could be more easily identied and reused across dierent models and also allows for the study of more general models than the ones in Hypothesis Class 1 For instance additional steps of postprocessing or of en coding of classical data into quantum states can be de scribed as additional maps to be composed and readily t in such framework Finally although in this manuscript we have exclusively focused on classication tasks ie where the model outputs scalars one can consider the more general setting of a model producing operator valued outputs ie in the case of quantum generative modeling 33 93 94 In such a case one would be interested in global equivariance of the model rather than invariance VII CONCLUSIONS In this work we presented a theoretical framework to de sign QML models that by construction respect the sym metries of a group G associated to the dataset This ap proach has several benets 7 it is more data ecient it reduces the models search space less parameters it often leads to better generalization and the classication accu racy is robust under perturbations drawn from the symme try group Our main contributions are as follows First in Propositions 14 we leveraged properties from repre sentation theory to determine the conditions that lead to Ginvariance These results constitute guidelines for de signing groupinvariant models and were used to show how models such as those in Hypothesis Class 1 can be made G invariant and accurately solve certain supervised learning tasks We then showcased the power of our framework for several QML tasks where we nd how embedding symme try information into the model allows us to recover in an elegant and formal way several algorithms from the litera ture that were heuristically obtained or that were obtained through trialanderror As a rst application we addressed the task of classi fying pure states from mixed states in conventional and quantumenhanced experiments ie experiments with and17 without access to a quantum memory For this case the symmetry group is the unitary group since applying a uni tary to a quantum state preserves its spectral properties Theorem 1 showed that there exist no conventional experi ments that are Ginvariant and that can classify the data in the purity dataset However by allowing the QML model to coherently act on two copies of each state in the dataset we showed in Theorem 2 that there exist models that are Ginvariant and can classify the data These are based on taking the expectation value of the SWAP operator which naturally appeared through the SchurWeyl duality as an element of the Symmetric group The second task we considered was that of classifying timereversal symmetric states from Haar random states In Theorems 3 and 4 we showed that models in both con ventional and quantumenhanced experiments can be used to distinguish such states Surprisingly we recovered the wellknown Bell basis measurement scheme for detecting timereversal where the Bell measurement operator ap peared naturally as an element of the basis of the Brauer algebra Moreover by the seemingly innocuous change of allowing the model to access the unitaries that prepare the states in the dataset rather than the states themselves we can obtain in Theorem 5 the model used in Ref 49 to show that quantumenhanced experiments can classify the data with exponentially less experiments than conventional experiments This connects our work with recent research showing that QML models are capable of exponential ad vantages in some tasks of data classication We then applied our framework to a dataset composed of pure states with dierent amounts of multipartite entangle ment Here the symmetry group preserving entanglement is the nfold direct product of the local unitary group This example proved the power of our framework as we showed that all the entanglement measures of Refs 3642 are special cases of the family of Ginvariant models dened in Theorem 7 Moreover we conjectured that allowing the QML model to access more than two copies of each quan tum state and measuring the expectation value of local permutation operators can lead to new entanglement mea sures Interestingly we recently became aware of the work in Ref 95 where it was shown such expectation values can indeed detect the presence entanglement Additionally we showed how our results extend beyond continuous Lie groups by studying a problem of classi cation in a quantum graph isomorphism dataset That is we addressed the task of determining if a given graph encoded quantum state belongs to one isomorphism class or the other In this case the symmetry group associated with the dataset is the Symmetric group In Theorem 8 we identied Ginvariant models capable of classifying the data in such graphisomorphism dataset Our results take one of the rst steps towards a general theory of QML models with sharp geometric priors based on the dataset symmetries Since our work is inspired by the theory and success of geometric deep learning we en vision that soon enough the eld of geometric quantum machine learning will be a thriving and exciting eld VIII OUTLOOK Here we overview some questions left unanswered by our results and propose dierent paths forward A Equivariance As detailed in Section VI the concept of equivariance in quantum neural networks may play a central role when building models that respect the symmetries of a given dataset While a few examples of equivariant quantum neural networks have been proposed such as the Quantum Convolutional Neural Network 21 which respects transla tional symmetry the Quantum Convolutional Graph Neu ral Network 32 which respects Snsymmetry in graphs the Udequivariant ansatz of 96 or the graph automor phism groupinvariant ansatz in 97 it is worth noting that these are the exception to the rule Most quantum neural networks in the literature are not equivariant and do not use information about symmetries in their design Hence much work remains to be done in the path towards general equivariant architectures especially to guarantee that they have circuit depth and connectivity requirements compat ible with nearterm quantum hardware B Trainability Expressibility and gradient magnitudes Arguably one of the main threats to the trainabil ity of QNNs are Barren Plateaus BPs a phenomenon by which gradients along the parameter landscape be come exponentially concentrated around zero as the sys tem size grows 1520 In the presence of BPs an expo nential number of measurement shots is required to cor rectly identify a minimizing direction on the landscape Given such limitations understanding the conditions that lead to their presence has been the subject of extensive work 17 22 23 25 98 Naively one would be tempted to choose QNNs to be highly expressive so that good approximations of the rele vant unitary transformation can be achieved Nevertheless Ref 15 unveiled a connection between the expressibility18 of an ansatz and the magnitudes of the gradients highly expressive anstze were shown to exhibit BPs suggesting that expressibility should be limited to give room for train ability Later on Ref 25 pointed towards the Lie closure of the gate generators of an ansatz as a measure of its ulti mate expressibility Most importantly when the dimension of such Lie closure grows exponentially with the system size as is the case for problemagnostic architectures such as the harware ecient ansatz 16 17 99 there exists some critical number of layers beyond which barren plateaus are known to dominate the parameter landscapes Finally we note that the size of the Lie closure has also been related to the number of parameters needed to overparametrize a QNN 26 Therefore given a xed number of parameters we expect in general less expressive ansatz to have more favourable landscapes Overall all these results point to wards the importance of reducing as much as possible in a sensible way the expressivity of QNNs In this context building models with strong geomet ric priors such as equivariant QNNs constitute a sensible choice By constraining the expressibility of the ansatz to the relevant region only these symmetrybased propos als emerge as goldilocks candidates for trainabilityaware ansatz design While the exact improvement in tranability will be certainly problem dependent there is already evi dence that equivariant QNNs do indeed lead to better per formance and trainability in several archetypal nearterm algorithms 97 C Generalization Complementary to its trainability the ability of a model to generalize to unseen data is key to its applicability in realistic scenarios While errors evaluated on a training dataset are the main metric when training a model its practical success should be gauged when applied to new testing data The generalization error quanties the gap between training and testing errors In the realm of QML recent results 24 have shown that such generalization er ror is upper bounded by a quantity scaling as TN where T denotes the number of parameters and N the number of training data As such given a xed training dataset reducing the expressibility of a model by means of equiv ariant QNNs with appropriate geometric priors and thus the number of free parameters is expected to yield better model generalization D Quantum advantage The gold standard for quantum machine learning mod els and for quantum algorithms in general is being able to solve a given task faster that any classical method As exemplied by our main results see Sec IV B the con cept of Ginvariance is not tied to that of computational advantage as there exists Ginvariant models capable but also incapable of achieving a quantum advantage Hence it will be fundamental to determine the key features that lead to models with favourable scalings E More general models and learning scenarios In this work we considered QML models of the form in Hypothesis Class 1 However these are not the most general models one can have For instance the ability to perform nontrivial postprocessing on the measurement outcomes 61 or employing randomized measurement tech niques 100 can greatly increase the models power and performance 13 We expect that the principles exposed here can be applied to more general settings opening up the possibility of obtaining Ginvariance with methods be yond those described in Propositions 14 Moreover while the concepts of kth order symmetries and orthogonal com plements played a key role in our derivation of Ginvariant models we expect that other properties will be needed to understand groupinvariance in more general settings Finally we highlight that we have mainly focused on su pervised tasks of binary classication Nevertheless the ideas of Ginvariance should also be applied to more general supervised learning scenarios including regression prob lems or to unsupervised learning scenarios IX ACKNOWLEDGMENTS We thank Robert Zeier for helpful and insightful discus sions ML and PJC were supported by the US Depart ment of Energy DOE Oce of Science Oce of Ad vanced Scientic Computing Research under the Acceler ated Research in Quantum Computing ARQC program ML was also supported by the Center for Nonlinear Stud ies at LANL PJC and MC were also initially supported by the LANL ASC Beyond Moores Law project FS was supported by the Laboratory Directed Research and Devel opment LDRD program of Los Alamos National Labora tory LANL under project number 20220745ER MC was supported by the LDRD program of LANL under project number 20210116DR This work was also supported by19 the Quantum Science Center QSC a National Quantum Information Science Research Center of the US Depart ment of Energy DOE X formerly known as Googlex is part of the Alphabet family of companies which includes Google Verily Waymo and others wwwxcompany 1 M GellMann Beauty truth and physics 2007 2 I Newton The Principia mathematical principles of nat ural philosophy Univ of California Press 1999 3 J C Maxwell Viii a dynamical theory of the electromag netic eld Philosophical transactions of the Royal Society of London 459 1865 4 A Einstein The general theory of relativity in The Mean ing of Relativity Springer 1922 pp 5475 5 D J Gross The role of symmetry in fundamental physics Proceedings of the National Academy of Sciences 93 14256 1996 6 E Noether Invariante variationsprobleme mathphys Klasse pp235257 1918 7 M M Bronstein J Bruna T Cohen and P Velikovi Geometric deep learning Grids groups graphs geodesics and gauges arXiv preprint arXiv210413478 2021 8 T Cohen and M Welling Group equivariant convolu tional networks in International conference on machine learning PMLR 2016 pp 29902999 9 R Kondor and S Trivedi On the generalization of equiv ariance and convolution in neural networks to the action of compact groups in International Conference on Machine Learning PMLR 2018 pp 27472755 10 A Bogatskiy S Ganguly T Kipf R Kondor D W Miller D Murnane J T Oermann M Pettee P Shanahan C Shimmin et al Symmetry group equivariant architectures for physics arXiv preprint arXiv220306153 2022 11 J Biamonte P Wittek N Pancotti P Rebentrost N Wiebe and S Lloyd Quantum machine learning Na ture 549 195 2017 12 M Cerezo A Arrasmith R Babbush S C Benjamin S Endo K Fujii J R McClean K Mitarai X Yuan L Cincio and P J Coles Variational quantum algo rithms Nature Reviews Physics 3 625644 2021 13 HY Huang R Kueng G Torlai V V Albert and J Preskill Provably ecient machine learning for quan tum manybody problems Science 377 eabk3333 2022 14 This is also known as the choice and parameterization of prior in the language of Bayesian theory 101 15 Z Holmes K Sharma M Cerezo and P J Coles Con necting ansatz expressibility to gradient magnitudes and barren plateaus PRX Quantum 3 010313 2022 16 J R McClean S Boixo V N Smelyanskiy R Babbush and H Neven Barren plateaus in quantum neural network training landscapes Nature Communications 9 1 2018 17 M Cerezo A Sone T Volko L Cincio and P J Coles Cost function dependent barren plateaus in shallow parametrized quantum circuits Nature Communications 12 1 2021 18 K Sharma M Cerezo L Cincio and P J Coles Train ability of dissipative perceptronbased quantum neural networks Physical Review Letters 128 180505 2022 19 S Thanasilp S Wang N A Nghiem P J Coles and M Cerezo Subtleties in the trainability of quantum ma chine learning models arXiv preprint arXiv211014753 2021 20 A Arrasmith Z Holmes M Cerezo and P J Coles Equivalence of quantum barren plateaus to cost concentration and narrow gorges arXiv preprint arXiv210405868 2021 21 I Cong S Choi and M D Lukin Quantum convolu tional neural networks Nature Physics 15 1273 2019 22 A Pesah M Cerezo S Wang T Volko A T Sorn borger and P J Coles Absence of barren plateaus in quantum convolutional neural networks Physical Review X 11 041011 2021 23 T Volko and P J Coles Large gradients via correlation in random parameterized quantum circuits Quantum Sci ence and Technology 6 025008 2021 24 M C Caro HY Huang M Cerezo K Sharma A Sorn borger L Cincio and P J Coles Generalization in quan tum machine learning from few training data Nature Communications 13 4919 2022 25 M Larocca P Czarnik K Sharma G Muraleedharan P J Coles and M Cerezo Diagnosing barren plateaus with tools from quantum optimal control arXiv preprint arXiv210514377 2021 26 M Larocca N Ju D GarcaMartn P J Coles and M Cerezo Theory of overparametrization in quantum neural networks arXiv preprint arXiv210911676 2021 27 D Wecker M B Hastings and M Troyer Progress to wards practical quantum variational algorithms Physical Review A 92 042303 2015 28 B T Gard L Zhu G S Barron N J Mayhall S E Economou and E Barnes Ecient symmetrypreserving state preparation circuits for the variational quantum eigensolver algorithm npj Quantum Information 6 1 2020 29 J Lee A B Magann H A Rabitz and C Arenz Progress toward favorable landscapes in quantum com binatorial optimization Physical Review A 104 032401 2021 30 H L Tang V Shkolnikov G S Barron H R Grim sley N J Mayhall E Barnes and S E Economou qubitadaptvqe An adaptive algorithm for constructing hardwareecient anstze on a quantum processor PRX20 Quantum 2 020310 2021 31 J R Glick T P Gujarati A D Corcoles Y Kim A Kandala J M Gambetta and K Temme Covari ant quantum kernels for data with group structure arXiv preprint arXiv210503406 2021 32 G Verdon T McCourt E Luzhnica V Singh S Le ichenauer and J Hidary Quantum graph neural net works arXiv preprint arXiv190912264 2019 33 G Verdon J Marks S Nanda S Leichenauer and J Hidary Quantum Hamiltonianbased models and the variational quantum thermalizer algorithm arXiv preprint arXiv191002071 2019 34 H Buhrman R Cleve J Watrous and R De Wolf Quan tum ngerprinting Physical Review Letters 87 167902 2001 35 J Cotler HY Huang and J R McClean Revisiting dequantization and quantum advantage in learning tasks arXiv preprint arXiv211200811 2021 36 J L Beckey N Gigena P J Coles and M Cerezo Com putable and operationally meaningful multipartite entan glement measures Phys Rev Lett 127 140501 2021 37 G K Brennen An observable measure of entanglement for pure states of multiqubit systems arXiv preprint quantph0305094 2003 38 D A Meyer and N R Wallach Global entanglement in multiparticle systems Journal of Mathematical Physics 43 4273 2002 39 P Rungta V Buek C M Caves M Hillery and G J Milburn Universal state inversion and concurrence in ar bitrary dimensions Physical Review A 64 042315 2001 40 V S Bhaskara and P K Panigrahi Generalized con currence measure for faithful quantication of multiparti cle pure state entanglement using lagranges identity and wedge product Quantum Information Processing 16 1 2017 41 A R R Carvalho F Mintert and A Buchleitner Deco herence and multipartite entanglement Phys Rev Lett 93 230501 2004 42 A Wong and N Christensen Potential multiparticle entanglement measure Physical Review A 63 044301 2001 43 I Hen and A Young Solving the graphisomorphism problem with a quantum annealer Physical Review A 86 042310 2012 44 F Gaitan and L Clark Graph isomorphism and adia batic quantum computing Physical Review A 89 022342 2014 45 K M Zick O Shehab and M French Experimental quantum annealing case study involving the graph iso morphism problem Scientic reports 5 1 2015 46 Z G Izquierdo R Zhou K Markstrm and I Hen Dis criminating nonisomorphic graphs with an experimental quantum annealer Physical Review A 102 032622 2020 47 We make here two important remarks First G must form a group as composing two symmetries leads to a new sym metry Similarly symmetric transformations are always invertible and their inverse is a symmetry itself Second in more precise terms G is a unitary representation of a group 48 E J Bekkers M W Lafarge M Veta K A Eppen hof J P Pluim and R Duits Rototranslation covariant convolutional networks for medical image analysis in In ternational conference on medical image computing and computerassisted intervention Springer 2018 pp 440 448 49 HY Huang M Broughton J Cotler S Chen J Li M Mohseni H Neven R Babbush R Kueng J Preskill and J R McClean Quantum advantage in learning from experiments Science 376 1182 2022 50 D Aharonov J Cotler and XL Qi Quantum algorith mic measurement Nature Communications 13 1 2022 51 M Cerezo K Sharma A Arrasmith and P J Coles Variational quantum state eigensolver npj Quantum In formation 8 1 2022 52 A Kirillov Jr An introduction to Lie groups and Lie al gebras 113 Cambridge University Press 2008 53 R Zeier and T SchulteHerbrggen Symmetry princi ples in quantum systems theory Journal of mathematical physics 52 113510 2011 54 Z Zimbors R Zeier T SchulteHerbrggen and D Burgarth Symmetry criteria for quantum simulability of eective interactions Physical Review A 92 042309 2015 55 A representation is irreducible if it cannot be further de composed into a direct sum of representations 56 B Collins and P niady Integration with respect to the haar measure on unitary orthogonal and symplec tic group Communications in Mathematical Physics 264 773 2006 57 Z Puchala and J A Miszczak Symbolic integration with respect to the haar measure on the unitary groups Bul letin of the Polish Academy of Sciences Technical Sciences 65 21 2017 58 N Cristianini J ShaweTaylor et al An introduction to support vector machines and other kernelbased learning methods Cambridge university press 2000 59 R Goodman and N R Wallach Symmetry representa tions and invariants Vol 255 Springer 2009 60 We refer the reader to 53 54 for an indepth discussion on the quadratic symmetries of Ud 61 L Cincio Y Suba A T Sornborger and P J Coles Learning the quantum algorithm for state overlap New Journal of Physics 20 113022 2018 62 R G Sachs The physics of time reversal University of Chicago Press 1987 63 S Chen J Cotler HY Huang and J Li Exponential separations between learning with and without quantum memory in 2021 IEEE 62nd Annual Symposium on Foun dations of Computer Science FOCS IEEE 2022 pp 574585 64 W Brown An algebra related to the orthogonal group University of MICHIGAN 1954 65 R Horodecki P Horodecki M Horodecki and K Horodecki Quantum entanglement Reviews of mod21 ern physics 81 865 2009 66 N Gigena M Di Tullio and R Rossignoli Onebody entanglement as a quantum resource in fermionic systems Physical Review A 102 042410 2020 67 J Barrett Nonsequential positiveoperatorvalued mea surements on entangled mixed states do not always violate a bell inequality Physical Review A 65 042302 2002 68 N Gigena and R Rossignoli Bipartite entanglement in fermion systems Physical Review A 95 062320 2017 69 A K Ekert Quantum cryptography based on bells the orem Physical Review Letters 67 661 1991 70 N Gisin G Ribordy W Tittel and H Zbinden Quan tum cryptography Reviews of modern physics 74 145 2002 71 A Ekert and R Jozsa Quantum algorithms entanglementenhanced information processing Philo sophical Transactions of the Royal Society of London Series A Mathematical Physical and Engineering Sciences 356 1769 1998 72 A Datta S T Flammia and C M Caves Entanglement and the power of one qubit Physical Review A 72 042316 2005 73 T Chalopin C Bouazza A Evrard V Makhalov D Dreon J Dalibard L A Sidorenkov and S Nascim bene Quantumenhanced sensing using nonclassical spin states of a highly magnetic atom Nature Communications 9 1 2018 74 J L Beckey M Cerezo A Sone and P J Coles Vari ational quantum algorithm for estimating the quantum Fisher information Physical Review Research 4 013083 2022 75 M Cerezo A Sone J L Beckey and P J Coles Sub quantum Fisher information Quantum Science and Tech nology 10108820589565abfbef 2021 76 M A Nielsen and I L Chuang Quantum Computation and Quantum Information Cambridge University Press Cambridge 2000 77 B M Terhal and K G H Vollbrecht Entanglement of formation for isotropic states Physical Review Letters 85 2625 2000 78 K G H Vollbrecht and R F Werner Entanglement measures under symmetry Physical Review A 64 062307 2001 79 M Walter D Gross and J Eisert Multipartite entangle ment Quantum Information From Foundations to Quan tum Technology Applications 293 2016 80 A Sawicki M Oszmaniec and M Kus Convexity of mo mentum map morse index and quantum entanglement Reviews in Mathematical Physics 26 1450004 2014 81 A Sawicki M Oszmaniec and M Kus Critical sets of the total variance can detect all stochastic local opera tions and classical communication classes of multiparticle entanglement Physical Review A 86 040304 2012 82 T Maciazek and A Sawicki Asymptotic properties of en tanglement polytopes for large number of qubits Journal of Physics A Mathematical and Theoretical 51 07LT01 2018 83 L Schatzki A Arrasmith P J Coles and M Cerezo Entangled datasets for quantum machine learning arXiv preprint arXiv210903400 2021 84 M Walter B Doran D Gross and M Christandl En tanglement polytopes multiparticle entanglement from singleparticle information Science 340 1205 2013 85 O Prove S Foulds and V Kendon Extending the con trolled swap test to higher dimensions arXiv preprint arXiv211204333 2021 86 S Foulds V Kendon and T P Spiller The controlled swap test for determining quantum entanglement Quan tum Science and Technology 2021 87 M A Rieel and A Van Daele The commutation theo rem for tensor products of von neumann algebras Bulletin of the London Mathematical Society 7 257 1975 88 C B Mendl and M M Wolf Unital quantum channels convex structure and revivals of Birkhos theorem Com munications in Mathematical Physics 289 1057 2009 89 J Kobler U Schning and J Torn The graph isomor phism problem its structural complexity Springer Science Business Media 2012 90 L Babai Graph isomorphism in quasipolynomial time in Proceedings of the fortyeighth annual ACM symposium on Theory of Computing 2016 pp 684697 91 R Goodman and N R Wallach Representations and invariants of the classical groups Cambridge University Press 2000 92 G Castelazo Q T Nguyen G De Palma D Englund S Lloyd and B T Kiani Quantum algorithms for group convolution crosscorrelation and equivariant transfor mations arXiv preprint arXiv210911330 2021 93 J Romero J P Olson and A AspuruGuzik Quantum autoencoders for ecient compression of quantum data Quantum Science and Technology 2 045001 2017 94 D Zhu N M Linke M Benedetti K A Landsman N H Nguyen C H Alderete A PerdomoOrtiz N Ko rda A Garfoot C Brecque et al Training of quantum circuits on a hybrid quantum computer Science advances 5 eaaw9918 2019 95 Z Liu Y Tang H Dai P Liu S Chen and X Ma De tecting entanglement in quantum manybody systems via permutation moments arXiv preprint arXiv220308391 2022 96 H Zheng Z Li J Liu S Strelchuk and R Kon dor Speeding up learning quantum states through group equivariant convolutional quantum ansatze arXiv preprint arXiv211207611 2021 97 F Sauvage M Larocca P J Coles and M Cerezo Build ing spatial symmetries into parameterized quantum cir cuits for faster training arXiv preprint arXiv220714413 httpsdoiorg1048550arXiv220714413 2022 98 E Grant L Wossnig M Ostaszewski and M Benedetti An initialization strategy for addressing barren plateaus in parametrized quantum circuits Quantum 3 214 2019 99 A Kandala A Mezzacapo K Temme M Takita M Brink J M Chow and J M Gambetta Hardware ecient variational quantum eigensolver for small22 molecules and quantum magnets Nature 549 242 2017 100 A Elben S T Flammia HY Huang R Kueng J Preskill B Vermersch and P Zoller The randomized measurement toolbox arXiv preprint arXiv220311374 2022 101 P W Battaglia J B Hamrick V Bapst A Sanchez Gonzalez V Zambaldi M Malinowski A Tacchetti D Raposo A Santoro R Faulkner et al Relational in ductive biases deep learning and graph networks arXiv preprint arXiv180601261 2018 102 J A Smolin and D P DiVincenzo Five twobit quan tum gates are sucient to implement the quantum fredkin gate Physical Review A 53 2855 1996 103 M Bilkis M Cerezo G Verdon P J Coles and L Cincio A semiagnostic ansatz with variable struc ture for quantum machine learning arXiv preprint arXiv210306712 2021 104 S Hadeld Z Wang B OGorman E G Rieel D Ven turelli and R Biswas From the quantum approximate optimization algorithm to a quantum alternating opera tor ansatz Algorithms 12 34 2019 105 E Farhi J Goldstone and S Gutmann A quan tum approximate optimization algorithm arXiv preprint arXiv14114028 201423 Appendices Here we present the additional details and proofs for some of the results in the main text Appendix A Hermitian part of the commutant Let us rst show that the following lemma holds Lemma 1 Let CkG denote the kth order symmetries of G Ud Then for any matrix A in CkG its Hermitian conjugate A is also in CkG Proof Let A be a matrix in CkG From Denition 5 we know that A is such that A V k 0 V G A1 The previous equation can be explicitly written as AV k V kA or equivalently as A V kAV k V G A2 Taking the conjugate transpose on each side leads to A V kAV k V G A3 which by Denition 5 implies that A is also in CkG As a consequence of Lemma A one can always associate a Hermitian operator to any matrix in CkG Namely if A CkG is Hermitian then nothing needs to be done But if A is not Hermitian one can create the operators AA and iA A which are Hermitian and which also belong to CkG Appendix B Proof of Proposition 2 Here we prove Proposition 2 of the main text which we recall for convenience Proposition 2 Let hk H1 be a model in Hypothesis Class 1 Then let G be the symmetry Lie group associated with the dataset and let g ud be its Lie algebra with i11 g The model will be Ginvariant when ig and O spanAj Ajj Here Aj ig is a Hermitian operator acting on the jth copy of and Aj is an operator acting on all copies of but the jth one Proof Let us rst consider the case when i11 g and when O Aj Aj for a given j If ig then rh with h ig and r R B1 Similarly if Aj ig we can write Aj ag with g ig and a R B2 It then follows from Denition 6 that TrAj ra Trhg 0 B324 since each term Trhg 0 From Eq B3 we know that the expectation value of O over k is hk Tr k O TrAj Trjk1Aj 0 B4 where Trj is the trace over all qubits except those in the jth copy of Equation B3 shows that hk 0 for all states having support exclusively on ig Since a Lie algebra is closed under the action of its Lie group then it follows that V V ig for all V G Thus with a similar argument we have hk V V Tr V V Aj TrjV V k1Aj 0 B5 for all V G where we used again Denition 6 The latter shows that hk is G invariant Finally we can generalize the previous results to the case when O spanAj Ajj Now we can expand O j ojAj Aj B6 If Aj ig j we nally nd hk V V Tr V V k O j oj Tr V V Aj TrjV V k1Aj 0 B7 which completes the proof We here nally note that if i11 g then we can obtain Ginvariance when ig and Aj ig The proofs follows similarly to that previously presented Now we have hk V V Tr V V k O j oj Tr V AjV TrjV V k1Aj 0 B8 Here we need to use the fact that Tr V AjV ig for all V G a Lie algebra is closed under the action of its associated Lie group Moreover we have used Denition 6 to show that Tr V AjV 0 Appendix C Proof of Propositions 3 and 4 Here we prove Propositions 3 and 4 Since their proofs follow from those of Propositions 1 and 2 respectively we simply mention the main dierences Proof First we recall that in Propositions 3 and 4 we consider the case when the data with dierent labels have dierent symmetry groups denoted as G0 and G1 Moreover each symmetry group will have their own kth order symmetries and for the case of Lie groups their associated Lie algebra and orthogonal complements From Proposition 1 we know that a model will be Ginvariant if O belongs to CkG Since here there are two symmetry groups we know that the models will be G0invariant if O belongs to CkG0 Evidently the model will also be G1 invariant if O is also in CkG1 Thus to guarantee G0invariance but not necessarily G1invariance one needs O to belong to G0 but not to G1 This constitutes the proof of Proposition 3 The proof of Proposition 4 follows similarly from that of Proposition 3 Here the model will be G0 and G1invariant if O spanAj Ajj ig0 ig1 and Aj ig 0 ig 1 In addition the model will be G01invariant but not necessarily G10invariant when ig0 igi and Aj ig 0 but Aj ig 125 Appendix D Ancillabased models for the purity dataset In the main text we considered the task of classifying the data in the purity dataset with models in Hypothesis Class 1 ie with models of the form h Tr UkU O As we saw in Theorem 1 of the main text there are no such models with k 1 that allow for classication On the other hand Theorem 2 shows that models with k 2 can indeed classify the data according to their purity In this case O has to be the SWAP operator up to some additive and multiplicative constants The previous raises the issue of how to eciently evaluate the expectation value of the SWAP operator Taking inspiration from the Hadamard Test which computes the expectation value of a unitary by controlling its action with an ancillary qubit we envision a new family of ancillabased hypothesis Here one appends to the QNN an extra qubit that is used along the two copies of so that the 2n 1 qubit state 00 is fed into a quantum neural network that acts globally on all qubits and only measures the ancilla qubit This denes the following Hypothesis class Hypothesis Class 3 We dene the Hypothesis Class H3 computable in a quantumenhanced experiment as composed of functions of the form h Tr U00 U OA D1 where U is a quantum neural network acting on 2n 1qubits and OA O 11 11 with O a onequbit Hermitian operator acting on the ancilla qubit The models in Hypothesis Class H3 now should be invariant under the action of 11 V V for any V in Ud In the spirit of Proposition 1 and dening OA U OAU we know that this can be readily achieved when OA 11 V V 0 for all V Ud that is when OA iu2 C2G This results in the following Theorem Theorem 9 Let h H3 be a model in Hypothesis Class 3 computable in a quantumenhanced experiment There always exist quantum neural networks U and operators OA resulting in OA A S where A 0 0 and S span11 11 SWAP with nonzero component in SWAP such that h is invariant under the action of Ud and can perfectly classify the data in the purity dataset The special choice of OA Z SWAP corresponds to the operator measured in the Swap Test 34 and in the ancilla based algorithm of 61 Proof We rst recall that the models in H3 will be Ginvariant if hV V h for all V Ud ie when Tr 11 V V 00 11 V V OA Tr 00 OA D2 This holds when OA 11 V V 0 D3 Eq D3 is satised for the choice of OA A S with A an operator acting on the ancillary qubit and S an operator in C2Ud spanS2 with S2 11 11 SWAP a representation of the Symmetric group of two elements Then replacing OA by A S in the lefthandside of D2 leads to Tr 11 V V 00 11 V V OA Tr 11 V V 00 11 V V A S Tr00 A S Tr00 A Tr S In the second inequality we have used the fact that S commutes with V V while in the third line we have simply separated the trace over the dierent subsystems Since replacing OA by A S in the lefthandside of D2 leads to Tr00 Tr S we can see that the model will be Ginvariant i A 0 0 ie if A has 0 as an eigenvector with eigenvalue equal to one Finally we remark that a direct calculation with the circuits in Fig 1 veries that both circuits satisfy U 1Z1111U1 U 2Z 11 11U2 Z SWAP Hence we recover the operator measured in the Swap Test 34 and in the ancilla based algorithm of 6126 Figure 1 Ancillabased circuits for computing the purity a The circuit U1 corresponds to the canonical SWAP test which was compiled into gates native to the IBMs superconducting qubit devices 102 Here H and T denotes the Hadamard and 8 phase gates respectively At the end of the circuit one measures the expectation value of the Pauli Z operator on the ancilla qubit b The circuit for U2 corresponds to the ancillabased algorithm for computing purity discovered in 61 trough a machine learning subroutine designed to minimize the number of CNOTs required see also 103 Here W T H At the end of the circuit one measures the expectation value of the Pauli Z operator on the ancilla qubit Both circuits satisfy the conditions in Theorem 2 as U 1Z 11 11U1 U 2Z 11 11U2 Z SWAP Let us analyze here the remarkable fact that the special choice A Z leads to the exact operator measured in two distinct ancillabased circuits computing the purity in the Swap Test 34 and in the algorithm discovered in 61 For completeness these two circuits are shown in Fig 1 for the case when is a single qubit state While both circuits endup computing the purity of they do so by implementing distinct unitaries This can be seen by evaluating the Schmidt rank across the ancilladata qubits cut of the two circuits This Schmidt rank is found to be 2 for the unitary U1 displayed in Fig 1a and 3 for the unitary U2 displayed in Fig 1b This indicates that both circuits are fundamentally dierent in the sense that there is no local operations that map one to the other 61 Still one can verify that U 1Z 11 11U1 U 2Z 11 11U2 A SWAP D4 where A Z Hence our results shed new light to the connection between these two circuits Appendix E Classifying with Eq 18 In the main text we argued that when the classication task has two symmetry groups associated with the two dierent classes then one can classify the data if there exists a G1invariant model hk H1 in the Hypothesis Class 1 such that hk i c if yi 1 hk i b1 b2 if yi 0 E1 When c b1 b2 one can readily use this model for unambiguous classication when the model returns a value of c dierent from c one would assign a label of y 1 y 0 which corresponds to the true label of the state to be classied However when c b1 b2 we can still perform classication but at the cost of misclassifying some of the states Indeed there will now be cases where one measures a value of hk i c despite the fact that the underlying state has true label yi 0 but assign it a label y 1 The probability of such misclassication event is quantied in the following Lemma 2 Let P0c be the probability of misclassication which happens when the true label of a state i is yi 0 given a model value hk i c Accordingly let Pc0 be the probability that the model takes a value of c when the data has label yi 0 Assuming equal probability of sampling states belonging to each of the two classes we have P0c Pc0 1 Pc0 E2 Lemma 2 shows that the probability of misclassication will remain small as long as the probability that hk i c given yi 0 is small Let us now provide a proof for Lemma 227 Proof We know from Bayes theorem that P0c P0Pc0 Pc E3 According to the law of total probability we have Pc Pc1P1 Pc0P0 where P0 and P1 denote the probability of sampling a state i with label yi 0 and yi 1 respectively Assuming the same representation of each label in the dataset ie P0 P1 12 we can rewrite Eq E3 as P0c 1 2Pc0 1 2 Pc1 Pc0 Pc0 Pc1 Pc0 E4 Finally recalling that when yi 1 the model outcome is always c we have Pc1 1 such that we recover E2 Going further we can bound this probability of misclassication if we know the expectation value and variance of hk i for states with label yi 0 First note that Pc0 0 such that according to E2 P0c Pc0 Next let us dene X to be the random variable corresponding to the QML model output ie X hk i for a random state i We denote as X0 Eyi0hk i the expectation value of this variable conditioned on the sampled states to have label yi 0 Assuming that this expectation value is greater than c without loss of generality and dening X0 c 0 we nd via Cantellis inequality that PX X Var0X Var0X 2 E5 where Var0X X20 X2 0 is the variance of X when sampling states with label yi 0 It follows that P0c Pc0 PX X Var0X Var0X 2 E6 showing that for large separation relative to the variance Var0X the misclassication error will be small Finally note that when taking into account additive errors when estimating the output of the model one would assign a label 1 for model values estimated in a range C c c In this case misclassication would arise when the model value is estimated in C despite the true label of the state being 0 and Equations E2 and E6 could readily be extended to this scenario Appendix F Concentration results for timereversal datasets In the previous section we have seen that one can classify the states in the dataset via Eq E1 and that for well separated expectation values for the two classes the misclassication probability can be small In other cases however it can happen that X0 Eyi0hk i c and that one would need a large number of experiment repetitions to guarantee an accurate classication Here we see that for some of the models considered in the main text such issue arises 1 Conventional experiments We recall from Theorem 3 that if O is a purely complex operator then h1 i 0 i such that yi 1 F1 We now show that values of h1 i for yi 0 exponentially concentrates around c 0 such that an exponential number of shots would be needed for classication 49 50 6328 First let us recall that the Haar random states i with yi 0 are obtained by evolving a duciary realvalued initial state in according to a Haar random unitary Wi i WiinW i F2 Thus we can evaluate the expectation value X0 Eyi0hk i by averaging the model predictions over the unitary group That is X0 EHaarh1 WiiW i This can be analytically derived via symbolical integration with respect to the Haar measure on a unitary group 57 For any W Ud the following expressions are valid for the rst two moments of the distribution Wd dUwi1j1w i2j2 i1i2j1j2 d Wd dUwi1j1wi2j2w i 1j 1w i 2j 2 i1i 1i2i 2j1j 1j2j 2 i1i 2i2i 1j1j 2j2j 1 d2 1 i1i 1i2i 2j1j 2j2j 1 i1i 2i2i 1j1j 1j2j 2 dd2 1 F3 where wij are the matrix elements of W Assuming d 2n we use the notation i i1 in to denote a bitstring of length n such that i1 i2 in 0 1 A straightforward calculation leads to X0 TrO d 0 F4 Here we have used the fact that O is Hermitian and purely imaginary and hence has no support on the identity operator Moreover we can also nd that Var0X X20 Tr O2 Tr 2 in d2 1 Tr O2 dd2 1 d Tr 2 in d2 1 1 dd2 1 F5 where in the last inequality we have further assumed that Tr O2 11 as this is the case when O is a tensor product of an odd number of Pauli Y operators Hence we can see that Var0X O 1 2n and thus that the values of the QML model when sampling Haar random states concentrate exponentially around its mean of zero 2 Quantumenhanced experiments We start by recalling that when classifying the states in the timereversal dataset we found that h2 i 02n2 1 d2 F6 for all i such that yi 1 and that h2 i Ui Ui02n2 F7 for all i such that yi 0 where Ui is the Haar random unitary that generates the state i Here we have assumed that in 00n An explicit calculation of the expectation value leads to X0 2 dd 1 F8 which shows that for large number of qubits X0 c O 1 2n Moreover explicit calculation of the variance shows as before that Var0X O 1 22n Hence the values of the QML model for Haar random states concentrate in a range exponentially close to zero29 Appendix G Quantum Graph Convolutional Neural Networks In this section we present additional details for the Quantum Graph Neural Networks QGNN and Quantum Graph Convolutional Neural Networks QGCNN architectures introduced in Ref 32 We start by introducing the general form of a QGNN and then show how it can be specialized to particular permutationinvariant datasets a General QGNN ansatz The most general QGNN ansatz is dened as Uqgnn P p1 Q q1 eipq Hq G1 which consists of a sequence of evolutions under Q dierent Hamilonians repeated P times with and the variational parameters The Hamiltonians Hq can be taken to be any parameterized Hamiltonians with interaction topology corresponding to the graph G V E Hq jkE rIjk Wqrjk Oqr j P qr k vV rJv Bqrv Rqvr v G2 Note that here the Wqrjk and Bqrv are tensors of realvalued parameters which are collected as one vector qjkrWqrjk qvr Bqrv The operators Rqvr j Oqr j P qr j are Hermitian and act on the Hilbert space of the jth node of the graph while the sets Ijk and Jv are index sets for the terms corresponding to the edges and nodes of the graph G respectively b Quantum Graph Convolutional Network QGCNN In order to ensure permutation invariance of the overall ansatz we can enforce the generators of the QGNN to all be permutation invariant This is achieved by tying some parameters across vertex indices of the graph we can then drop such indices and the coecients become Wqrjk Wqr and Bqrv Bqr resulting in Hq jkE rI Wqr Oqr j Oqr k vV rJ Bqr Rqr v G3 where I and J are index sets that are edge and nodeindependent These Hamiltonian generators of our QGNN layers are invariant under any permutation of the node indices which preserve the edge structure as boths sums indices can be relabelled We call QGNNs of the form G1 with generators of the form G3 Quantum Graph Convolutional Neural Networks QGCNNs and note that they are general forms of the socalled Quantum Alternating Operator Ansatze 104 and of the Quantum Approximate Optimization Algorithm 105